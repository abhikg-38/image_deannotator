{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7fedcd-a269-4928-9a5e-3284535ccb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height:500,weight:500,channels:3\n",
      "Number of total contours:\n",
      "98\n",
      "Dog contour:\n",
      "705\n",
      "Height:500,weight:500,channels:3\n",
      "Number of total contours:\n",
      "134\n",
      "Dog contour:\n",
      "2750\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def resize_img(img):\n",
    "    return(cv2.resize(img,(500,500)))\n",
    "    \n",
    "def get_output_image(original_image_path,fully_annotated_image_path,partially_annotated_image_path):\n",
    "    if not isinstance(original_image_path,(str, list)):\n",
    "        raise TypeError(\"image path must be either string or list data type\")\n",
    "    if not isinstance(fully_annotated_image_path,(str, list)):\n",
    "        raise TypeError(\"image path must be either string or list data type\")\n",
    "    if not isinstance(partially_annotated_image_path,(str, list)):\n",
    "        raise TypeError(\"image path must be either string or list data type\")\n",
    "    fully_annotated=cv2.imread(fully_annotated_image_path)#reads the fully annotated image from its path\n",
    "    fully_annotated=resize_img(fully_annotated)#resizes image\n",
    "    cv2.imshow('Fully annotated image',fully_annotated)#displays image\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    height,width,channels=fully_annotated.shape\n",
    "    print(f'Height:{height},weight:{width},channels:{channels}')#prints height, width and color channels\n",
    "    \n",
    "    gray_fa=cv2.cvtColor(fully_annotated, cv2.COLOR_BGR2GRAY)#converts image to grayscale\n",
    "    clahe=cv2.createCLAHE(clipLimit=1.0099,tileGridSize=(8,8))#helps enhance contrast, window size is 8x8\n",
    "    gray_fa=clahe.apply(gray_fa)\n",
    "\n",
    "    #cv2.imshow('Enhanced gray scale image of the fully annotated image:', clahe_fa)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "    #adaptive_threshold = cv2.adaptiveThreshold(gray_fa, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    gray_fa=cv2.GaussianBlur(gray_fa,(5,5),0)#gaussian blur used to smooth out noise, sd=0,5x5 kernel size\n",
    " \n",
    "    edges=cv2.Canny(gray_fa,50,150)#used for edge detection\n",
    "    #gradient>150 threshold= strong edges, <50= weak edges\n",
    "    cv2.imshow('Edge detection',edges)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    kernel=np.ones((3,3),np.uint8)#defines neighbourhood considered for pixel dilation\n",
    "    edges=cv2.dilate(edges,kernel,iterations=1)#enhances boundaries of image on edge extracted image\n",
    "\n",
    "    cv2.imshow('Dilation:',edges)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()#displays image after dilation\n",
    "\n",
    "    contours, _=cv2.findContours(edges,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)#finds contours of edges, RETR_LIST collects\n",
    "    #all contours irrespective of nesting hierarchy\n",
    "    #print('Number of filtered contours:')\n",
    "    #print(len(filtered_contours))\n",
    "    print('Number of total contours:')\n",
    "    print(len(contours))\n",
    "\n",
    "    filtered_contours=[]\n",
    "    for contour in contours:\n",
    "        if len(contour)>= 5:\n",
    "            x,y,w,h=cv2.boundingRect(contour)#fits a rectangle to the contour\n",
    "            aspect_ratio=w/h\n",
    "            aspect_ratio_threshold=2#calculates threshold value for aspect ratio\n",
    "            if aspect_ratio<aspect_ratio_threshold:\n",
    "                filtered_contours.append(contour)#appends to list if condition satisfies\n",
    "    sorted_filtered_contours=sorted(filtered_contours,key=cv2.contourArea,reverse=True)#amongst the filtered contours, the\n",
    "    #i=ones having greatest area of put at the start\n",
    "    dog_contour=sorted_filtered_contours[0]\n",
    "    fa=fully_annotated.copy()\n",
    "    print('Dog contour:')\n",
    "    print(len(dog_contour))#logically, the contour having largest area is chosen as the one to be de annotated\n",
    "\n",
    "    cv2.drawContours(fa,[dog_contour],-1,(255,0,0),2)\n",
    "    cv2.imshow('Drawn contours:',fa)#extracted contours drawn over image\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    mask=np.zeros_like(gray_fa) #mask originally kept as a black image\n",
    "    cv2.drawContours(mask,[dog_contour],-1,(255),thickness=cv2.FILLED)\n",
    "    #thickness=cv2.FILLED means that annotated region filled with white, zeros initially is a black image with same dimensions as og\n",
    "\n",
    "    result = cv2.inpaint(fully_annotated,mask,inpaintRadius=5,flags=cv2.INPAINT_TELEA)#filles annotation region\n",
    "    #telea's method retains underlying structure\n",
    "    cv2.imshow('Image after partial deannotation',result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    cv2.imwrite(partially_annotated_image_path,result)#stores the image in its path\n",
    "\n",
    "get_output_image('C:/Personal/ML/datasets/img9/original_image.jpg',\n",
    "                 'C:/Personal/ML/datasets/img9/fully_annotated_image.jpg',\n",
    "                 'C:/Personal/ML/datasets/img9/partially_annotated_image.jpg')\n",
    "\n",
    "get_output_image('C:/Personal/ML/datasets/img13/original_image.jpg',\n",
    "                 'C:/Personal/ML/datasets/img13/fully_annotated_image.jpg',\n",
    "                 'C:/Personal/ML/datasets/img13/partially_annotated_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de1b887-00d1-4162-b3e1-964bf2c5a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139a5e8-eac4-4f34-92cb-78dafa730ebf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be49e6-fee1-4ad3-a1c9-5f929146bc29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb8b87-cb0c-47c3-b22e-c1d444aa3666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
